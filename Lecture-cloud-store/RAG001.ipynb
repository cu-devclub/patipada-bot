{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3363b0-260f-4198-8de0-87cfa0828720",
   "metadata": {
    "id": "6b3363b0-260f-4198-8de0-87cfa0828720"
   },
   "source": [
    "# หัวข้อ : สร้าง RAG สำหรับภาษาไทย ด้วย OpenSource\n",
    "\n",
    "#### จัดทำโดยทีม [VulturePrime](https://vultureprime.com)\n",
    "\n",
    "## รายละเอียด\n",
    "การสร้าง RAG เริ่มต้นเป็น Use case ที่แพร่หลายสำหรับการนำ AI เข้ามาประยุกต์ใช้กับธุรกิจ\n",
    "แต่เนื่องจากความขาดแคลนตัวอย่างที่เหมาะสมของแต่ละภาษา ทำให้เกิดปัญหา 2 ปัญหาได้แก่\n",
    "1. English centric ตัวอย่างส่วนใหญ่จะถูกทำขึ้นมาโดยใช้ภาษาอังกฤษเป็นศูนย์กลาง ทำให้ภาษาอื่นนั้น จำเป็นต้องประยุกต์ Solution ขึ้นมาเองซึ่งทำให้ Developer ต้องลงทุนในการเรียนรู้เพิ่มขึ้นอย่างมหาศาล ไม่ว่าจะเป็นในเรื่องของ Tokenizer หรือ Text splitter\n",
    "2. OpenAI centric เนื่องจากการเชื่อมต่อกับ OpenAI API นั้นเป็นเรื่องที่ใช้ Effort ต่ำสุดและมีประสิทธิภาพสูงที่สุด ทำให้ AI และ Embedding Model อื่นนั้น กลายเป็น 3rd class citizen เมื่อนักพัฒนาอยากลดรายจ่ายโดยใช้ AI และ Embedding รายอื่น จึงเป็นเรื่องที่มีต้นทุนสูงอย่างมหาศาล (Switching cost)  \n",
    "\n",
    "จากปัญหาทั้ง 2 ปัญหาทำให้เกิด AI Adoption ที่ช้ากว่าและแพงกว่าบริษัทที่ใช้ภาษาอังกฤษ​เป็นภาษาหลัก\n",
    "\n",
    "จึงเป็นที่มาของการสร้าง Use case ด้วยโปรเจคตัวอย่าง เพื่อให้ Developer สามารถลด Learning curve ลงไปได้\n",
    "และส่งเสริมให้มีความรวดเร็วในการนำ AI ไปใช้เพิ่มประสิทธิของ Feature ที่มีอยู่แล้วหรือสร้าง Feature ใหม่ขึ้นมา\n",
    "\n",
    "## บทความเพิ่มเติม (ภาษาไทย)\n",
    "- [Driving a Q&A Bot Project](https://www.vultureprime.com/blogs/driving-a-q-a-bot-project-a-product-owners-guide)\n",
    "\n",
    "## Benefit\n",
    "- ราคาต่อ Character ที่ถูกกว่า 90 - 95% เมื่อเทียบกับ OpenAI\n",
    "- เวลาในการประมวลผลที่น้อยลงเหลือเพียง 1/3 ถึง 1/4 (Float16 API หรือ SLA ตามต้องการ)\n",
    "- สามารถใช้งาน Offline หรือ Private เองได้\n",
    "\n",
    "## ความท้าทาย\n",
    "- การนับจำนวน Token ที่ไม่เท่ากันของภาษาอังกฤษและภาษาอื่น ทำให้ต้องสร้าง Custom Helper function เพื่อให้รองรับภาษาอื่น\n",
    "- การตัดประโยคของภาษาไทยเมื่อเทียบกับภาษาอื่น\n",
    "- การใช้งาน OpenSource เช่น Huggingface Embedding และ OpenAI API-like\n",
    "- การใช้งาน Vector Database และทำความเข้าใจ Parameter ในการค้นหา\n",
    "\n",
    "## Environment\n",
    "- [LlamaIndex](https://www.llamaindex.ai/) (Data Framework)\n",
    "- [Weaviate](https://weaviate.io/) (Vector Database)\n",
    "- [SeaLLM-7b](https://huggingface.co/SeaLLMs/SeaLLM-7B-Chat) (AI Model) ใช้งานผ่าน [Float16.cloud](https://float16.cloud)\n",
    "- [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large) (Embedding Model)\n",
    "\n",
    "## Flow\n",
    "1. บันทึกข้อมูลรูปแบบ String Text ไปยัง Vector Database\n",
    "2. ค้นหาข้อมูลจาก Vector Database และนำไปใช้กับ AI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b20ba8-acba-475d-913c-d5ecfac38177",
   "metadata": {
    "id": "d3b20ba8-acba-475d-913c-d5ecfac38177"
   },
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466ef30-3bfb-4eb9-9aee-295b0f3ef623",
   "metadata": {
    "id": "7466ef30-3bfb-4eb9-9aee-295b0f3ef623"
   },
   "source": [
    "#### 1.เก็บข้อมูลรูปแบบ String Text ไปยัง Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa03704-cd15-41ee-befe-b8f6cabbc36b",
   "metadata": {
    "id": "aaa03704-cd15-41ee-befe-b8f6cabbc36b"
   },
   "outputs": [],
   "source": [
    "#ทำการ Import Library ที่จำเป็น\n",
    "from llama_index.core import ServiceContext, StorageContext,VectorStoreIndex,Document\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "#เชื่อมต่อกับ Vector Database\n",
    "auth_config = weaviate.AuthApiKey(api_key=\"R59jaGzJguJrS9ohXZomzPwK5Vb4OYUcDXYi\")\n",
    "client = weaviate.Client(\n",
    "  url=\"https://monkbot001-t6uc4fwa.weaviate.network\",\n",
    "  auth_client_secret=auth_config\n",
    ")\n",
    "\n",
    "#กำหนดชื่อ Document สำหรับ String Text ที่ต้องการบันทึกใน Vector Database\n",
    "document_name = 'Read_document'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf100132",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"read.txt\", \"r\", encoding=\"utf-8\") as Read_document:\n",
    "    Read_document = Read_document.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e25ed829-5e57-4eb1-acea-08300bf56912",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7e6c68815df147a594cda2dacec233b4",
      "4123b96127bd409fb1b406e1b842d027",
      "7deffd3448044e11a79d73a7a761fd1e",
      "bb64f7d3932d49ea97d104b4519c4d1f",
      "4003134500714b8981970839a3e8cdb1",
      "7f2f813672144271b88e04a287d73adc",
      "5bca17e98a4048a6ab0f54b8126f0b6b",
      "190f03616a1049edb8d13265bb424e85",
      "dd7a628bd4b04313a62670cbec672bc1",
      "fe7dcd8902db4e4ea1dc4c2c2cce4da2",
      "83a726cc00f442d1afe00dda16ef1d00"
     ]
    },
    "id": "e25ed829-5e57-4eb1-acea-08300bf56912",
    "outputId": "532d50f4-a672-48e8-837b-abc20d1cf458"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#กำหนดค่าของ Text Splitter ที่ต้องการใช้\n",
    "#Chunk size กำหนดถึงความยาวของ Text ที่ต้องการตัด และ Chunk overlap หมายถึงการคาบเกี่ยวของ Text แต่ละชุดให้คาบเกี่ยวกับชุดก่อนหน้ามากน้อยแค่ไหน\n",
    "text_parser = TokenTextSplitter.from_defaults(chunk_overlap=192,chunk_size=384)\n",
    "\n",
    "#ประมวลผล String Text ให้กลายเป็น List[String] โดย String มีขนาดตามที่กำหนดจากขั้นตอนก่อนหน้านี้\n",
    "nodes = text_parser.get_nodes_from_documents(\n",
    "    [Document(text=Read_document)], show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e90e2206-f0ae-42c4-95ac-00b14b33e8fd",
   "metadata": {
    "id": "e90e2206-f0ae-42c4-95ac-00b14b33e8fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukpi\\AppData\\Local\\Temp\\ipykernel_20012\\1545560160.py:11: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "#openai.api_key = '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'\n",
    "\n",
    "#กำหนดชื่อ Embedding model ที่รองรับภาษาไทย\n",
    "embedding_model_name = \"intfloat/multilingual-e5-small\"\n",
    "\n",
    "#Download Embedding Model จาก Huggingface\n",
    "embed_model = HuggingFaceEmbedding(model_name=embedding_model_name,max_length=384)\n",
    "\n",
    "#กำหนดให้ใช้งาน Embedding ที่ทำการ Download มาจาก Huggingface\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "\n",
    "#กำหนดชื่อสำหรับ text key สำหรับการค้นหา\n",
    "text_key = 'content'\n",
    "\n",
    "#สร้าง VectorStore Node\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client,index_name = document_name,text_key = text_key)\n",
    "\n",
    "#กำหนดให้ใช้งาน VectorDatabase ที่ทำการเชื่อมต่อกับ Weaviate\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd9a50a-6a69-4fb5-834a-f3e5775fec8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fd9a50a-6a69-4fb5-834a-f3e5775fec8f",
    "outputId": "9e55403c-fda7-41d9-93a1-3a72310daf14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x1f1f81623f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#นำ List[String] ที่ได้จากขั้นตอนประมวลผล Text นำมาแปลงให้อยู่ในรูปของ List[Vector]\n",
    "#แปลง String เป็น Vector โดยใช้ Embedding Model intfloat/multilingual-e5-small\n",
    "#หลังจากได้ List[Vector] และ List[String] ให้นำข้อมูลดังกล่าวเก็บไว้ยัง VectorDatabase ที่ได้เชื่อมต่อไว้แล้ว\n",
    "#โดยเก็บไว้ใน Document ชื่อ Read_document และมี Text_key เริ่มต้นด้วย \"content\"\n",
    "VectorStoreIndex(nodes=nodes,storage_context=storage_context, service_context = service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362962d0-b817-4a59-aeef-083ec5963c0d",
   "metadata": {
    "id": "362962d0-b817-4a59-aeef-083ec5963c0d"
   },
   "source": [
    "#### 2. ค้นหาข้อมูลจาก Vector Database และนำไปใช้กับ AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade561d2-d06b-4905-a306-5ec83f8a2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d230f3f3-b632-4974-9036-7b529d9bb894",
   "metadata": {
    "id": "d230f3f3-b632-4974-9036-7b529d9bb894"
   },
   "outputs": [],
   "source": [
    "#ทำการ Import Library ที่จำเป็น\n",
    "from llama_index.llms import openai_like\n",
    "\n",
    "import weaviate\n",
    "from llama_index.readers.weaviate import WeaviateReader\n",
    "from llama_index.core import ServiceContext, ListIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "from llama_index.core.indices.prompt_helper import PromptHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6375705a-518d-4421-9cfe-bd9a2a6fb418",
   "metadata": {
    "id": "6375705a-518d-4421-9cfe-bd9a2a6fb418"
   },
   "outputs": [],
   "source": [
    "#ทำการ Config API ที่ต้องการใช้\n",
    "OPENAI_KEY = 'key'\n",
    "FLOAT16_API_KEY = 'float16-56hBpTpGA5VYSs13Awe9U1FjGaTo5pNODx67cnI066EBP5rewr'\n",
    "FLOAT16_CUSTOM_URL = 'https://api.float16.cloud/v1/llamaindex'\n",
    "WEAVIATE_ENDPOINT = \"https://monkbot001-t6uc4fwa.weaviate.network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27500c47-0b1b-479a-8388-5c627850f4ce",
   "metadata": {
    "id": "27500c47-0b1b-479a-8388-5c627850f4ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukpi\\anaconda3\\envs\\monkbot001\\Lib\\site-packages\\weaviate\\warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.5.4.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#เชื่อมต่อกับ VectorDatabase\n",
    "auth_config = weaviate.AuthApiKey(api_key=\"R59jaGzJguJrS9ohXZomzPwK5Vb4OYUcDXYi\")\n",
    "\n",
    "client = weaviate.Client(\n",
    "  url=\"https://monkbot001-t6uc4fwa.weaviate.network\",\n",
    "  auth_client_secret=auth_config\n",
    ")\n",
    "\n",
    "reader = WeaviateReader(\n",
    "    \"https://monkbot001-t6uc4fwa.weaviate.network\",\n",
    "    auth_client_secret=auth_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cfcf059-3b3b-4427-a05d-53e9a5dc4fdf",
   "metadata": {
    "id": "3cfcf059-3b3b-4427-a05d-53e9a5dc4fdf"
   },
   "outputs": [],
   "source": [
    "#สร้าง GraphQL query schema สำหรับการค้นหาข้อมูลที่เกี่ยวข้องจาก VectorDatabase\n",
    "query_schema = \"\"\"\n",
    "{{\n",
    "  Get{{\n",
    "    {document_name}(\n",
    "      nearVector: {{\n",
    "        vector: {vector_question},\n",
    "        certainty: {certainty}\n",
    "      }}\n",
    "      limit : {limit}\n",
    "    ) {{\n",
    "      {text_key}\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55dd6a73-968b-4c7b-bf35-6ecae0bd9ac0",
   "metadata": {
    "id": "55dd6a73-968b-4c7b-bf35-6ecae0bd9ac0"
   },
   "outputs": [],
   "source": [
    "#กำหนดชื่อ Embedding model ที่รองรับภาษาไทย\n",
    "embedding_model_name = \"intfloat/multilingual-e5-small\"\n",
    "\n",
    "#Download Embedding Model จาก Huggingface\n",
    "embed_model = HuggingFaceEmbedding(model_name=embedding_model_name,max_length=384)\n",
    "\n",
    "#ระบุคำถามที่ต้องการถาม AI\n",
    "question = \"อุเทสิกเจดีย์คืออะไร\"\n",
    "\n",
    "#เปลี่ยนคำถาม (String) ให้กลายเป็น Vector\n",
    "vector_question = embed_model._embed(question)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2e4eb71-bab7-4be2-83ca-2c3e19c87296",
   "metadata": {
    "id": "c2e4eb71-bab7-4be2-83ca-2c3e19c87296"
   },
   "outputs": [],
   "source": [
    "#กำหนดชื่อ Document สำหรับ String Text ที่ต้องการบันทึกใน Vector Database\n",
    "document_name = 'Read_document'\n",
    "\n",
    "#กำหนดชื่อสำหรับ text key สำหรับการค้นหา\n",
    "text_key = 'content'\n",
    "\n",
    "#ทำการ map ตัวแปรเข้ากับ Schema\n",
    "query = query_schema.format(\n",
    "  document_name=document_name,\n",
    "  vector_question=vector_question,\n",
    "  certainty=0.95,\n",
    "  text_key=text_key,\n",
    "  limit=1\n",
    ")\n",
    "\n",
    "#ส่งคำสั่ง query ไปยัง VectorDatabase\n",
    "documents = reader.load_data(graphql_query=query, separate_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04f6b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='dad864b7-e7b6-484a-bae5-ab92d17a5de2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='content: เครื่องสักการะเครื่องบูชาใครไปนั่งตรงนั้นก็ได้รับการสักการะบูชา เพราะว่าผู้แสดงธรรมเป็นผู้ที่ควรแก่สักการะบูชา ที่เรียกว่าอุเทสิกเจดีย์เค้าเรียกว่าเป็นสิ่งที่ควรค่า ไม่ได้ว่าจะเป็นเฉพาะพระภิกษุนะฆราวาสเองก็ตาม ถ้าเขาจัดตั้งการบูชาไว้ก็คือต้องการบูชาอุเทสิกเจดีย์\\nอุเทสิกเจดีย์ตัวนี้ไม่มีวัตถุปรากฏ แต่เป็นสิ่งที่เนื่องด้วยพระตถาคต คำว่าสิ่งที่เนื่องด้วยพระตถาคตคือการแสดงธรรม เพราะอุเทสิกมีความหมายว่าการยกขึ้น', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e1571-2768-4c90-b808-9aa81aa0c9b3",
   "metadata": {
    "id": "0c1e1571-2768-4c90-b808-9aa81aa0c9b3"
   },
   "source": [
    "#### กำหนด Service ที่เกี่ยวข้องกับ AI\n",
    "\n",
    "llm คือการกำหนดให้ใช้งาน LLM ตัวใดหรือผู้ให้บริการเจ้าใดสำหรับการรับ Prompt เพื่อให้ตอบคำถาม\n",
    "\n",
    "embed_model คือการกำหนดให้ใช้งาน Embedding ตัวใด สำหรับการแปลง Text ให้เป็น Vector\n",
    "\n",
    "prompt_helper คือตัวช่วยจิปาถะที่เกี่ยวข้องกับการใช้งาน LLM เช่น การทำให้ Prompt ที่ส่งไปยังผู้ให้บริการมีขนาดไม่เกินที่กำหนด (max_context)\n",
    "\n",
    "หรือ เมื่อ Prompt มีขนาดยาวเกินไปก็จะทำการ \"ตัดข้อมูล\" โดยอัตโนมัติ\n",
    "\n",
    "สำหรับ context_window ที่เรากำหนดขึ้นมานั้นมีขนาด 10,000 token ซึ่งการนับ Token โดย Default นั้น ใช้งาน Tiktoken หรือ OpenAI ในการนับ Token\n",
    "\n",
    "ทำให้ไม่สอดคล้องกับ SeaLLM-7b เนื่องจาก SeaLLM-7b นับ Token ต่างกับ OpenAI\n",
    "\n",
    "ส่งผลให้เมื่อใช้งาน context_window default จะทำให้ข้อมูลขาดหายไปบางช่วง\n",
    "\n",
    "DEFAULT context_window = 3900 #token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6487c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ระบุ model ที่ต้องการใช้งาน\n",
    "llm_model_name = \"seallm-7b-v2\"\n",
    "\n",
    "#เชื่อมต่อกับ Float16\n",
    "agent = openai_like.OpenAILike(\n",
    "    api_key=FLOAT16_API_KEY,\n",
    "    api_base=FLOAT16_CUSTOM_URL,\n",
    "    model=llm_model_name,\n",
    "    temperature=0.3,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0f365cf-9f49-415b-8c47-448c73f1b65f",
   "metadata": {
    "id": "a0f365cf-9f49-415b-8c47-448c73f1b65f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukpi\\AppData\\Local\\Temp\\ipykernel_2868\\2458241909.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=agent,embed_model=embed_model,prompt_helper=PromptHelper(context_window=10000))\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=agent,embed_model=embed_model,prompt_helper=PromptHelper(context_window=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6738a7c-9dd9-4c33-8a2a-13f0ff83796f",
   "metadata": {
    "id": "a6738a7c-9dd9-4c33-8a2a-13f0ff83796f"
   },
   "outputs": [],
   "source": [
    "#สร้าง index สำหรับการค้นหาข้อมูลจาก ผลลัพธ์จาก query\n",
    "index = ListIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b69955-9f99-487c-acd2-214e15f19ac2",
   "metadata": {
    "id": "b7b69955-9f99-487c-acd2-214e15f19ac2"
   },
   "source": [
    "#### กำหนด Prompt pipeline สำหรับ RAG\n",
    "\n",
    "Default สำหรับ Llamaindex จะเป็นการ \"refine\" ซึ่ง refine จะเป็นขั้นตอนการทำงาน 2 ขั้นตอนต่อกัน\n",
    "1. Question and Answer เพื่อให้ LLM ที่กำหนดไว้ใน Service_context ตอบคำถาม\n",
    "2. Refine เพื่อให้คำตอบที่ได้ออกมานั้นสวยงามมากยิ่งขึ้น\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "989bce91-eaf7-4945-b813-77eb3fca99e9",
   "metadata": {
    "id": "989bce91-eaf7-4945-b813-77eb3fca99e9"
   },
   "outputs": [],
   "source": [
    "#กำหนด Prompt pipeline สำหรับ RAG\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "      response_mode=\"simple_summarize\",service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e089a97-92c8-40c6-9ec1-943ec8db15a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e089a97-92c8-40c6-9ec1-943ec8db15a3",
    "outputId": "9cbf647c-32b5-4cd7-d29e-7ee2d12ca6ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: เครื่องสักการะเครื่องบูชาใครไปนั่งตรงนั้นก็ได้รับการสักการะบูชา เพราะว่าผู้แสดงธรรมเป็นผู้ที่ควรแก่สักการะบูชา ที่เรียกว่าอุเทสิกเจดีย์เค้าเรียกว่าเป็นสิ่งที่ควรค่า ไม่ได้ว่าจะเป็นเฉพาะพระภิกษุนะฆราวาสเองก็ตาม ถ้าเขาจัดตั้งการบูชาไว้ก็คือต้องการบูชาอุเทสิกเจดีย์\n",
      "อุเทสิกเจดีย์ตัวนี้ไม่มีวัตถุปรากฏ แต่เป็นสิ่งที่เนื่องด้วยพระตถาคต คำว่าสิ่งที่เนื่องด้วยพระตถาคตคือการแสดงธรรม เพราะอุเทสิกมีความหมายว่าการยกขึ้น\n",
      "result : อุเทสิกเจดีย์เป็นสิ่งที่ควรค่าและควรได้รับการสักการะบูชา ไม่ว่าจะเป็นพระภิกษุหรือฆราวาส ถ้ามีการจัดตั้งการบูชาอุเทสิกเจดีย์ขึ้นมา มันแสดงถึงการแสดงธรรม ซึ่งเป็นสิ่งที่เนื่องด้วยพระตถาคต\n"
     ]
    }
   ],
   "source": [
    "#สร้าง Query engine จาก index ที่เราได้สร้างจาก ผลลัพธ์จาก Query และเปลี่ยน Response ให้ทำงานแค่ 1 ขั้นตอน\n",
    "query_engine = index.as_query_engine(\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    service_context=service_context,\n",
    ")\n",
    "\n",
    "#ค้นหาผลลัพธ์จาก RAG\n",
    "result = query_engine.query(\"<summarization_query_thai>\")\n",
    "print(documents[0].text)\n",
    "print(\"result :\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b914ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "190f03616a1049edb8d13265bb424e85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4003134500714b8981970839a3e8cdb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4123b96127bd409fb1b406e1b842d027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f2f813672144271b88e04a287d73adc",
      "placeholder": "​",
      "style": "IPY_MODEL_5bca17e98a4048a6ab0f54b8126f0b6b",
      "value": "Parsing nodes: 100%"
     }
    },
    "5bca17e98a4048a6ab0f54b8126f0b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7deffd3448044e11a79d73a7a761fd1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_190f03616a1049edb8d13265bb424e85",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd7a628bd4b04313a62670cbec672bc1",
      "value": 1
     }
    },
    "7e6c68815df147a594cda2dacec233b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4123b96127bd409fb1b406e1b842d027",
       "IPY_MODEL_7deffd3448044e11a79d73a7a761fd1e",
       "IPY_MODEL_bb64f7d3932d49ea97d104b4519c4d1f"
      ],
      "layout": "IPY_MODEL_4003134500714b8981970839a3e8cdb1"
     }
    },
    "7f2f813672144271b88e04a287d73adc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83a726cc00f442d1afe00dda16ef1d00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb64f7d3932d49ea97d104b4519c4d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe7dcd8902db4e4ea1dc4c2c2cce4da2",
      "placeholder": "​",
      "style": "IPY_MODEL_83a726cc00f442d1afe00dda16ef1d00",
      "value": " 1/1 [00:00&lt;00:00, 11.71it/s]"
     }
    },
    "dd7a628bd4b04313a62670cbec672bc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe7dcd8902db4e4ea1dc4c2c2cce4da2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
